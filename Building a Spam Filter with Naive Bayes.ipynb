{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdcc5a2e",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes\n",
    "The goal of this project is to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. We aim to achieve an accuracy rate greater than 80%, meaning more than 80% of new messges will be classified correctly as either spam or non-spam.\n",
    "\n",
    "To build our spam filter, we must:\n",
    "1) Teach an algorithm how humans classify messages as either spam or non-spam.\n",
    "2) Have the algorithm use that knowledge to estimate the probabilitity a new messages is either spam or non-spam.\n",
    "3) Use these probabilities to classify the new message based on the following criteria: \n",
    "     - If the probability of spam is greater than non-spam, then spam\n",
    "     - If the probability of non-spam is greater than spam, then non-spam\n",
    "     - If the two probability are equal, then we may need a human to classify the message.\n",
    "\n",
    "To teach the algorithm for step 1, we'll be using a dataset of 5,572 SMS messages that are already classified by humans. The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). The data collection process is described in more details on [this page](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition), where you can also find some of the papers authored by Tiago A. Almeida and José María Gómez Hidalgo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60482fa",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "Note: The dataset uses the word *ham* to represent non-spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf81fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SMS messages: 5,572\n",
      "Number of missing values in the dataframe: 0\n",
      "\n",
      "SMS dataset - Spam vs. ham, %\n",
      "+-------+------+\n",
      "| Label |  %   |\n",
      "+-------+------+\n",
      "|  ham  | 87.0 |\n",
      "| spam  | 13.0 |\n",
      "+-------+------+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "sms = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "\n",
    "print(f'Number of SMS messages: {sms.shape[0]:,}')\n",
    "print(f'Number of missing values in the dataframe: {sms.isnull().sum().sum()}\\n')\n",
    "\n",
    "def pretty_print_table(df, df_name):\n",
    "    print(f'{df_name} dataset - Spam vs. ham, %')\n",
    "    spam_ham_pct = round(df['Label'].value_counts(normalize=True)*100, 0)\n",
    "    print(spam_ham_pct.to_markdown(tablefmt='pretty', headers=['Label', '%']))\n",
    "\n",
    "pretty_print_table(df=sms, df_name='SMS')\n",
    "\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf2078",
   "metadata": {},
   "source": [
    "## Training and Test Set\n",
    "To ensure our algorithm reaches the desired accuracy rate of greater than 80%, we'll need to have a set of data to test against. Luckily, our dataset is large enough to comfortabily split into 2 parts:\n",
    "- a training set used for teaching the algorithm how to classify messages.\n",
    "- a test set used for checking the accuracy rate of the algorith.\n",
    "\n",
    "We want our training set to be as large as possible while not compromising too much test data, so we'll use 80% (i.e. 4,458 messages) of the data for training, and 20% (i.e. 1,114 messages) for testing purposes.\n",
    "\n",
    "We'll begin by randomizing the dataset to ensure that spam and ham messages are spread properly throughout both sets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f77085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_randomized = sms.sample(frac=1, random_state=1)\n",
    "\n",
    "# Creating training set (80%)\n",
    "training_set = sms_randomized[:4458].reset_index(drop=True)\n",
    "# Creating test set (20%)\n",
    "test_set = sms_randomized[4458:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d513f7",
   "metadata": {},
   "source": [
    "We'll next analyze the percentage of spam and ham messages in the training and test datasets to ensure they're represenative of the whole dataset. We expect the percentages to be close to 87% of messages as ham, and the remaining 13% as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ce620c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset - Spam vs. ham, %\n",
      "+-------+------+\n",
      "| Label |  %   |\n",
      "+-------+------+\n",
      "|  ham  | 87.0 |\n",
      "| spam  | 13.0 |\n",
      "+-------+------+\n",
      "\n",
      "\n",
      "Test dataset - Spam vs. ham, %\n",
      "+-------+------+\n",
      "| Label |  %   |\n",
      "+-------+------+\n",
      "|  ham  | 87.0 |\n",
      "| spam  | 13.0 |\n",
      "+-------+------+\n"
     ]
    }
   ],
   "source": [
    "pretty_print_table(df=training_set, df_name='Training')\n",
    "print('\\n')\n",
    "pretty_print_table(df=test_set, df_name='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c0d538",
   "metadata": {},
   "source": [
    "The results look good! We can now move onto cleaning both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e746e",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "To allow our algorithm to calculate the probabilities, we'll first perform some data cleaning to format the data such that we can easily extract the information we need. This format will be our current table altered in the following ways:\n",
    "- All punctuation in the `SMS` column will be removed.\n",
    "- All words in the `SMS` column will be converted to lowercase.\n",
    "- We will add a series of new columns to represent each unique word in the vocabulary. For each row, these columns will contain the number of times their corresponding word appeared in the `SMS` column.\n",
    "\n",
    "![New format example](images/new_format_example.png)\n",
    "\n",
    "### Letter Case and Punctuation\n",
    "First, we'll remove the punctuation and bring all the words to lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7fb8d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before cleaning\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d59bd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After cleaning\n",
    "training_set['SMS'] = training_set['SMS'].str.replace('\\W', ' ', regex=True)\n",
    "training_set['SMS'] = training_set['SMS'].str.lower()\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34920d4",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary\n",
    "Next, we'll create the vocabulary, as in a list of all the unique words that occur in the messages of our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c81176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the vocabulary of the training set: 7,783\n"
     ]
    }
   ],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for sms in training_set['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))\n",
    "\n",
    "print(f'Number of unique words in the vocabulary of the training set: {len(vocabulary):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2760a",
   "metadata": {},
   "source": [
    "### The Final Training Set\n",
    "We're now going to use the vocabulary we just created to add new columns for each unique word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f4ae2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>damn</th>\n",
       "      <th>yay</th>\n",
       "      <th>destiny</th>\n",
       "      <th>buzz</th>\n",
       "      <th>sugardad</th>\n",
       "      <th>mm</th>\n",
       "      <th>0844</th>\n",
       "      <th>02085076972</th>\n",
       "      <th>barrel</th>\n",
       "      <th>mundhe</th>\n",
       "      <th>...</th>\n",
       "      <th>barcelona</th>\n",
       "      <th>applausestore</th>\n",
       "      <th>him</th>\n",
       "      <th>ain</th>\n",
       "      <th>kiss</th>\n",
       "      <th>nvm</th>\n",
       "      <th>praying</th>\n",
       "      <th>08452810075over18</th>\n",
       "      <th>firmware</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   damn  yay  destiny  buzz  sugardad  mm  0844  02085076972  barrel  mundhe  \\\n",
       "0     0    0        0     0         0   0     0            0       0       0   \n",
       "1     0    0        0     0         0   0     0            0       0       0   \n",
       "2     0    0        0     0         0   0     0            0       0       0   \n",
       "\n",
       "   ...  barcelona  applausestore  him  ain  kiss  nvm  praying  \\\n",
       "0  ...          0              0    0    0     0    0        0   \n",
       "1  ...          0              0    0    0     0    0        0   \n",
       "2  ...          0              0    0    0     0    0        0   \n",
       "\n",
       "   08452810075over18  firmware  loss  \n",
       "0                  0         0     0  \n",
       "1                  0         0     0  \n",
       "2                  0         0     0  \n",
       "\n",
       "[3 rows x 7783 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index]+=1\n",
    "        \n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f846f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>damn</th>\n",
       "      <th>yay</th>\n",
       "      <th>destiny</th>\n",
       "      <th>buzz</th>\n",
       "      <th>sugardad</th>\n",
       "      <th>mm</th>\n",
       "      <th>0844</th>\n",
       "      <th>02085076972</th>\n",
       "      <th>...</th>\n",
       "      <th>barcelona</th>\n",
       "      <th>applausestore</th>\n",
       "      <th>him</th>\n",
       "      <th>ain</th>\n",
       "      <th>kiss</th>\n",
       "      <th>nvm</th>\n",
       "      <th>praying</th>\n",
       "      <th>08452810075over18</th>\n",
       "      <th>firmware</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  damn  yay  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]     0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...     0    0   \n",
       "2   ham                    [welp, apparently, he, retired]     0    0   \n",
       "3   ham                                           [havent]     0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...     0    0   \n",
       "\n",
       "   destiny  buzz  sugardad  mm  0844  02085076972  ...  barcelona  \\\n",
       "0        0     0         0   0     0            0  ...          0   \n",
       "1        0     0         0   0     0            0  ...          0   \n",
       "2        0     0         0   0     0            0  ...          0   \n",
       "3        0     0         0   0     0            0  ...          0   \n",
       "4        0     0         0   0     0            0  ...          0   \n",
       "\n",
       "   applausestore  him  ain  kiss  nvm  praying  08452810075over18  firmware  \\\n",
       "0              0    0    0     0    0        0                  0         0   \n",
       "1              0    0    0     0    0        0                  0         0   \n",
       "2              0    0    0     0    0        0                  0         0   \n",
       "3              0    0    0     0    0        0                  0         0   \n",
       "4              0    0    0     0    0        0                  0         0   \n",
       "\n",
       "   loss  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "281ebb7c",
   "metadata": {},
   "source": [
    "## Calculating Constants First\n",
    "Now that we're done cleaning the training set, and we can begin creating the spam filter. We will do so by using the Naive Bayes algorithm to be able to classify new messages, which will need to answer these two probability questions:\n",
    "\n",
    "![Naive Bayes Formula 1](images/Naive_Bayes_1.png)\n",
    "\n",
    "To calculate P(wi|Spam) and P(wi|Ham) inside the formulas above, we'll need to use these equations:\n",
    "\n",
    "![Naive Bayes Formula 2](images/Naive_Bayes_2.png)\n",
    "\n",
    "where:\n",
    "- *N<sub>w<sub>i</sub>|Spam</sub>* — the number of times the word *w<sub>i</sub>* occurs in spam messages\n",
    "- *N<sub>w<sub>i</sub>|Ham</sub>* — the number of times the word *w<sub>i</sub>* occurs in ham messages\n",
    "- *N<sub>Spam</sub>* — total number of words in spam messages\n",
    "- *N<sub>Ham</sub>* — total number of words in ham messages\n",
    "- *N<sub>Vocabulary</sub>* — total number of unique words in the vocabulary\n",
    "- *α* — a smoothing parameter\n",
    "\n",
    "Some of the terms in the four equations above will have the same value for every new message. We can calculate the value of these terms once and avoid doing the computations again when a new messages comes in. Below, we'll use our training set to calculate:\n",
    "- *P(Spam)*\n",
    "- *P(Ham)*\n",
    "- *N<sub>Spam</sub>*\n",
    "- *N<sub>Ham</sub>*\n",
    "- *N<sub>Vocabulary</sub>*\n",
    "\n",
    "We'll also use Laplace smoothing and set *α*=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e5e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_spam: 0.13\n",
      "p_ham: 0.87\n",
      "n_spam: 15,190\n",
      "n_ham: 57,237\n",
      "n_vocabulary: 7,783\n",
      "alpha: 1\n"
     ]
    }
   ],
   "source": [
    "# Isolating spam and ham messages first\n",
    "spam_sms = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_sms = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_sms) / len(training_set_clean)\n",
    "p_ham = len(ham_sms) / len(training_set_clean)\n",
    "\n",
    "# N_Spam\n",
    "n_words_per_spam_sms = spam_sms['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_sms.sum()\n",
    "\n",
    "# N_Ham\n",
    "n_words_per_ham_sms = ham_sms['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_sms.sum()\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1\n",
    "\n",
    "print(f'p_spam: {p_spam:.2f}\\n'\n",
    "      f'p_ham: {p_ham:.2f}\\n'\n",
    "      f'n_spam: {n_spam:,}\\n'\n",
    "      f'n_ham: {n_ham:,}\\n'\n",
    "      f'n_vocabulary: {n_vocabulary:,}\\n'\n",
    "      f'alpha: {alpha}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f9f7d4",
   "metadata": {},
   "source": [
    "## Calculating Parameters\n",
    "The parameters *P(w<sub>i</sub>|Spam)* and *P(w<sub>i</sub>|Ham)* can vary between individual words, but they remain constant for each new message. For example, the word \"free\" is more likely to appear in a spam message than the word \"apply\", but the probability that the word \"free\" appears in a spam message does not change. This means we can save a lot of time by using our training set to calculate *P(w<sub>i</sub>|Spam)* and *P(w<sub>i</sub>|Ham)* for each word in our vocabulary beforehand to cut down on repeated calculations. This makes the Naive Bayes algorithm very fast compared to other algorithms, allowing us to almost instantly classify the new message.\n",
    "\n",
    "There are 7,783 words in our vocabulary, therefore calculating both types of probabilities means we need to calculate a total of 15,566 probabilities.\n",
    "\n",
    "The parameters are calculated using the formulas:\n",
    "\n",
    "![Naive Bayes Formula 2](images/Naive_Bayes_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf11096",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wi_spam = {}\n",
    "p_wi_ham = {}\n",
    "\n",
    "for word in vocabulary:\n",
    "    p_wi_spam[word] = (spam_sms[word].sum()+alpha)/(n_spam+alpha*n_vocabulary)\n",
    "    p_wi_ham[word] = (ham_sms[word].sum()+alpha)/(n_ham+alpha*n_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce68405",
   "metadata": {},
   "source": [
    "## Classifying A New Message\n",
    "Now that we have all our parameters calculated, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "- Takes in as input a new message.\n",
    "- Calculates *P(Spam|message)* and *P(Ham|message)* using the following formulas:\n",
    "![Naive Bayes Formula 1](images/Naive_Bayes_1.png)\n",
    "- Compares both values and:\n",
    "    - if *P(Ham|message)* > *P(Spam|message)*, then the message is classified as ham,\n",
    "    - if *P(Ham|message)* < *P(Spam|message)*, then the message is classified as spam,\n",
    "    - if *P(Ham|message)* = *P(Spam|message)*, then the algorithm may request human help.\n",
    "    \n",
    "If a new message contains some words that are not in the vocabulary, these words will be simply ignored for calculating the probabilities.\n",
    "\n",
    "Let's create our function and test them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b11fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message, print_prob=False):\n",
    "    '''Takes in a message as a string, calculates P(Spam|message) \n",
    "    and P(Ham|message), then compares the two values and classifies\n",
    "    the message as spam or ham, or requires human classification. \n",
    "    '''\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in p_wi_spam:\n",
    "            p_spam_given_message *= p_wi_spam[word]\n",
    "            \n",
    "        if word in p_wi_ham:\n",
    "            p_ham_given_message *= p_wi_ham[word]\n",
    "            \n",
    "    if print_prob:\n",
    "        print('P(Spam|message):', p_spam_given_message)\n",
    "        print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65247a3c",
   "metadata": {},
   "source": [
    "To test our function, we'll write spam and ham messages that share several words. Let's see if our algorithm can tell the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d458294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.9489855841968855e-26\n",
      "P(Ham|message): 5.055981709510022e-31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spam message\n",
    "classify(\"Urgent! Dave, you have won a free gift. Call now!\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4e1ec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.5471085373049283e-34\n",
      "P(Ham|message): 2.471877453192144e-32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ham message\n",
    "classify(\"Hi Dave, can you give me a call now? It's urgent.\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fabef5",
   "metadata": {},
   "source": [
    "Great! Looks like our algorithm classified these messages correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10d9c7",
   "metadata": {},
   "source": [
    "##  Measuring the Spam Filter's Accuracy\n",
    "Let's check how well the spam filter does on our test set of 1,114 messages. For the algorithm, each message in this dataset is new since we didn't use it for training. The output will be a classification label for every message, which we'll be able to compare with the actual label given by a human. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cdc8c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS Predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Predicted'] = test_set['SMS'].apply(classify)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ccfc2",
   "metadata": {},
   "source": [
    "Now, we'll measure the accuracy of our spam filter by comparing the predicted values with the actual ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "391ba267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1100\n",
      "Incorrect: 14\n",
      "Accuracy: 0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_set)\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['Predicted']:\n",
    "        correct += 1\n",
    "\n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbadc29",
   "metadata": {},
   "source": [
    "Excellent! Our spam filter looked at 1,114 messages and classified 1,100 correctly. That's an accuracy rate of 0.9874%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc6374",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this project, we managed to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. The filter has an accuracy rate of 98.74%, which exceeds our intial goal of over 80%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
